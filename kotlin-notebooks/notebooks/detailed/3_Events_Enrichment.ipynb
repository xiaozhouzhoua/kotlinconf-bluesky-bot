{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Enriching Filtered Events"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this notebook, we'll enrich the filtered events from the previous notebook with additional information. We'll use a combination of techniques to enrich the events:\n",
    "\n",
    "1. Topic modeling using a Large Language Model (LLM) to extract topics from the posts\n",
    "2. Creating embeddings for semantic search using a transformer model\n",
    "3. Storing the enriched events in Redis for querying\n",
    "\n",
    "\n",
    "\n",
    "Embeddings are vector representations of text that capture semantic meaning. They allow us to perform semantic search, which is a search based on meaning rather than exact keyword matching. In this notebook, we'll create embeddings for posts and store them in Redis for later querying.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.131978Z",
     "start_time": "2025-05-25T10:19:55.055538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%use coroutines\n",
    "@file:DependsOn(\"redis.clients:jedis:6.0.0\")"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions from Previous Notebooks"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating a Redis Client"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.151731Z",
     "start_time": "2025-05-25T10:19:55.134215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.JedisPooled\n",
    "\n",
    "val jedisPooled = JedisPooled()"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Stream Events"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.217740Z",
     "start_time": "2025-05-25T10:19:55.154071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.resps.StreamEntry\n",
    "\n",
    "data class Event(\n",
    "    val did: String,\n",
    "    val rkey: String,\n",
    "    val text: String,\n",
    "    val timeUs: String,\n",
    "    val operation: String,\n",
    "    val uri: String,\n",
    "    val parentUri: String,\n",
    "    val rootUri: String,\n",
    "    val langs: List<String>,\n",
    ") {\n",
    "    companion object {\n",
    "        fun fromMap(entry: StreamEntry): Event {\n",
    "            val fields = entry.fields\n",
    "            return Event(\n",
    "                did = fields[\"did\"] ?: \"\",\n",
    "                rkey = fields[\"rkey\"] ?: \"\",\n",
    "                text = fields[\"text\"] ?: \"\",\n",
    "                timeUs = fields[\"timeUs\"] ?: \"\",\n",
    "                operation = fields[\"operation\"] ?: \"\",\n",
    "                uri = fields[\"uri\"] ?: \"\",\n",
    "                parentUri = fields[\"parentUri\"] ?: \"\",\n",
    "                rootUri = fields[\"rootUri\"] ?: \"\",\n",
    "                langs = fields[\"langs\"]?.replace(\"[\", \"\")?.replace(\"]\", \"\")?.split(\", \") ?: emptyList()\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Consumer Group"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.243639Z",
     "start_time": "2025-05-25T10:19:55.220219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.StreamEntryID\n",
    "\n",
    "fun createConsumerGroup(streamName: String, groupName: String) {\n",
    "    try {\n",
    "        jedisPooled.xgroupCreate(streamName, groupName, StreamEntryID(\"0-0\"), true)\n",
    "    } catch (e: Exception) {\n",
    "        println(\"Consumer group already exists\")\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Bloom Filter"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.266780Z",
     "start_time": "2025-05-25T10:19:55.245931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun createBloomFilter(name: String) {\n",
    "    try {\n",
    "        jedisPooled.bfReserve(name, 0.01, 1000000)\n",
    "    } catch (e: Exception) {\n",
    "        println(\"Bloom filter already exists\")\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from Stream"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.300334Z",
     "start_time": "2025-05-25T10:19:55.269416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.params.XReadGroupParams\n",
    "\n",
    "fun readFromStream(\n",
    "    streamName: String,\n",
    "    consumerGroup: String,\n",
    "    consumer: String, count: Int\n",
    "): List<Map.Entry<String, List<StreamEntry>>> {\n",
    "    return jedisPooled.xreadGroup(\n",
    "        consumerGroup,\n",
    "        consumer,\n",
    "        XReadGroupParams().count(count),\n",
    "        mapOf(\n",
    "            streamName to StreamEntryID.XREADGROUP_UNDELIVERED_ENTRY\n",
    "        )\n",
    "    ) ?: emptyList()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Consume Stream"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.372515Z",
     "start_time": "2025-05-25T10:19:55.302559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlinx.coroutines.*\n",
    "\n",
    "fun consumeStream(\n",
    "    streamName: String,\n",
    "    consumerGroup: String,\n",
    "    consumer: String,\n",
    "    handlers: List<(Event) -> Pair<Boolean, String>>,\n",
    "    ackFunction: ((String, String, StreamEntry) -> Unit),\n",
    "    count: Int = 5,\n",
    "    limit: Int = 5\n",
    ") {\n",
    "    var lastMessageTime = System.currentTimeMillis()\n",
    "    var consumed = 0\n",
    "\n",
    "    while (consumed < limit) {\n",
    "        val entries = readFromStream(streamName, consumerGroup, consumer, count)\n",
    "        val allEntries = entries.flatMap { it.value }\n",
    "        allEntries.map { entry ->\n",
    "            consumed++\n",
    "            val event = Event.fromMap(entry)\n",
    "\n",
    "            for (handler in handlers) {\n",
    "                val (shouldContinue, message) = handler(event)\n",
    "                ackFunction(streamName, consumerGroup, entry)\n",
    "\n",
    "                if (!shouldContinue) {\n",
    "                    println(\"$consumer: Handler stopped processing: $message\")\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if (allEntries.isEmpty()) {\n",
    "            val now = System.currentTimeMillis()\n",
    "            if (now - lastMessageTime >= 2_000) {\n",
    "                println(\"$consumer: No new messages for 2 seconds. Stopping.\")\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Deduplicate"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.420083Z",
     "start_time": "2025-05-25T10:19:55.376448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun deduplicate(bloomFilter: String): (Event) -> Pair<Boolean, String> {\n",
    "    return { event ->\n",
    "        if (jedisPooled.bfExists(bloomFilter, event.uri)) {\n",
    "            Pair(false, \"${event.uri} already processed\")\n",
    "        } else {\n",
    "            Pair(true, \"OK\")\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.466254Z",
     "start_time": "2025-05-25T10:19:55.423424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.Connection\n",
    "import redis.clients.jedis.JedisPool\n",
    "import redis.clients.jedis.Transaction\n",
    "\n",
    "val jedisPool = JedisPool()\n",
    "\n",
    "fun ackAndBfFn(bloomFilter: String):  (String, String, StreamEntry) -> Unit {\n",
    "    return { streamName, consumerGroup, entry ->\n",
    "        jedisPool.resource.use { jedis ->\n",
    "            // Create a transaction\n",
    "            val multi = jedis.multi()\n",
    "\n",
    "            // Acknowledge the message\n",
    "            multi.xack(\n",
    "                streamName,\n",
    "                consumerGroup,\n",
    "                entry.id\n",
    "            )\n",
    "\n",
    "            // Add the URI to the bloom filter\n",
    "            multi.bfAdd(bloomFilter, Event.fromMap(entry).uri)\n",
    "\n",
    "            // Execute the transaction\n",
    "            multi.exec()\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.498382Z",
     "start_time": "2025-05-25T10:19:55.473625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val printUri: (Event) -> Pair<Boolean, String> = {\n",
    "    println(\"Got event from ${it.uri}\")\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Topic Modeling with Large Language Models\n",
    "Topic modeling is a technique used to discover abstract topics in a collection of documents. In this notebook, we'll use a Large Language Model to extract topics from posts. This will allow us to categorize posts and make them more searchable."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting Up the Ollama API Client\n",
    "We'll use the Spring AI Ollama client to interact with the Ollama API.\n",
    "\n",
    "Ollama is a tool that allows us to run large language models locally."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.735267Z",
     "start_time": "2025-05-25T10:19:55.511451Z"
    }
   },
   "cell_type": "code",
   "source": "@file:DependsOn(\"org.springframework.ai:spring-ai-ollama:1.0.0\")",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The prompt we'll use for the LLM is designed to extract software-related topics from posts. The prompt includes examples of how to format the output and what types of topics to include."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.760288Z",
     "start_time": "2025-05-25T10:19:55.738500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "val topicExtractorSystemPrompt = File(\"../resources/topic-extractor-prompt.txt\").readText()"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the Ollama Chat Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.797174Z",
     "start_time": "2025-05-25T10:19:55.765135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.ollama.OllamaChatModel\n",
    "import org.springframework.ai.ollama.api.OllamaApi\n",
    "import org.springframework.ai.ollama.api.OllamaApi.ChatRequest\n",
    "import org.springframework.ai.ollama.api.OllamaApi.Message\n",
    "import org.springframework.ai.ollama.api.OllamaApi.Message.Role\n",
    "import org.springframework.ai.ollama.api.OllamaOptions\n",
    "\n",
    "val ollamaApi = OllamaApi.builder()\n",
    "    .baseUrl(\"http://localhost:11434\")\n",
    "    .build()\n",
    "\n",
    "val ollamaOptions = OllamaOptions.builder().model(\"deepseek-coder-v2\").build()\n",
    "\n",
    "val ollamaChatModel = OllamaChatModel.builder()\n",
    "    .ollamaApi(ollamaApi)\n",
    "    .defaultOptions(ollamaOptions)\n",
    "    .build()"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Topic Modeling Function\n",
    "This function takes a post as input and uses the Ollama API to extract topics from the post. The function returns a string of comma-separated topics."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:19:55.839504Z",
     "start_time": "2025-05-25T10:19:55.799984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.chat.messages.SystemMessage\n",
    "import org.springframework.ai.chat.messages.UserMessage\n",
    "import org.springframework.ai.chat.prompt.Prompt\n",
    "\n",
    "fun extractTopics(post: String, existingTopics: String): String {\n",
    "    // Build a chat message\n",
    "    val messages = listOf(\n",
    "        SystemMessage(topicExtractorSystemPrompt),\n",
    "        UserMessage(\"Existing topics: $existingTopics\"),\n",
    "        UserMessage(\"Post: $post\")\n",
    "    )\n",
    "\n",
    "    val response = ollamaChatModel.call(Prompt(messages))\n",
    "    return response.result.output.text ?: \"\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:01.061338Z",
     "start_time": "2025-05-25T10:19:55.845423Z"
    }
   },
   "cell_type": "code",
   "source": "extractTopics(\"Kotlin is a great programming language for beginners who want to do Applied AI Engineering\", \"\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       " “Programming Languages, Beginner Guides, AI Programming, Kotlin”"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:01.202989Z",
     "start_time": "2025-05-25T10:20:01.074274Z"
    }
   },
   "cell_type": "code",
   "source": "extractTopics(\"Kotlin is a great programming language for beginners\", \"\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       " \"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:01.383166Z",
     "start_time": "2025-05-25T10:20:01.210954Z"
    }
   },
   "cell_type": "code",
   "source": "extractTopics(\"Brazilian samba is a great music genre for dancing\", \"\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       " \"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Counting how many times a topic appears"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Count-min sketch is a probabilistic data structure used for estimating the frequency of events in a stream of data.\n",
    "\n",
    "It is particularly useful for counting the number of occurrences of items in a large dataset without storing all the items explicitly."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:01.438676Z",
     "start_time": "2025-05-25T10:20:01.389420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.exceptions.JedisDataException\n",
    "import java.time.LocalDateTime\n",
    "\n",
    "fun createTopK(): String {\n",
    "    val windowBucket = LocalDateTime.now().withMinute(0).withSecond(0).withNano(0)\n",
    "    try {\n",
    "        jedisPooled.topkReserve(\"topics-topk:$windowBucket\", 15, 3000, 10, 0.9)\n",
    "    } catch (_: JedisDataException) {\n",
    "        println(\"TopK already exists\")\n",
    "    }\n",
    "\n",
    "    return \"topics-topk:$windowBucket\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a Topic Extraction Handler\n",
    "This function creates a handler that extracts topics from an event's text and stores them in Redis. The topics are stored as a pipe-separated string in the \"topics\" field of the event's hash."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:01.616436Z",
     "start_time": "2025-05-25T10:20:01.442376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val extractTopics: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    val existingTopics = jedisPooled.smembers(\"topics\")\n",
    "    val topics = extractTopics(event.text, existingTopics.joinToString(\", \"))\n",
    "        .replace(\"\\\"\", \"\")\n",
    "        .replace(\"“\", \"\")\n",
    "        .replace(\"”\", \"\")\n",
    "        .split(\",\")\n",
    "        .map { it.trim() }\n",
    "        .filter { it.isNotBlank() }\n",
    "\n",
    "    val topKKey = createTopK()\n",
    "    if (topics.isNotEmpty()) {\n",
    "        val filteredTopics = topics.filter { it.isNotBlank() }\n",
    "        jedisPooled.topkAdd(topKKey, *filteredTopics.toTypedArray())\n",
    "        jedisPooled.hset(\"post:\" + event.uri.replace(\"at://did:plc:\", \"\"), mapOf(\"topics\" to filteredTopics.joinToString(\"|\")))\n",
    "        jedisPooled.sadd(\"topics\", *filteredTopics.toTypedArray())\n",
    "    }\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:36:57.241033Z",
     "start_time": "2025-05-25T20:36:57.223325Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"filtered-events\", \"topic-extraction-example\")",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:36:43.167526Z",
     "start_time": "2025-05-25T20:36:43.144123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val bloomFilterName = \"topic-extraction-bf\"\n",
    "createBloomFilter(bloomFilterName)"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:37:10.000188Z",
     "start_time": "2025-05-25T20:36:58.264856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"filtered-events\",\n",
    "        consumerGroup = \"topic-extraction-example\",\n",
    "        consumer = \"topic-extraction-1\",\n",
    "        handlers = listOf(deduplicate(bloomFilterName), printUri, extractTopics),\n",
    "        ackFunction = ackAndBfFn(bloomFilterName),\n",
    "        count = 1,\n",
    "        limit = 1000\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got event from at://did:plc:a2d7wyznodetv6djnhqpkhrb/app.bsky.feed.post/3lpygpd4tnc2f\n",
      "Got event from at://did:plc:eilzlr5373mba7tiwkaadmar/app.bsky.feed.post/3lpygpcrnak25\n",
      "TopK already exists\n",
      "Got event from at://did:plc:s33lmvk7rwmlypc2qm6wn2lr/app.bsky.feed.post/3lpygozydiko2\n",
      "TopK already exists\n",
      "Got event from at://did:plc:hx5shg2yhkm2dtnr4gh265lb/app.bsky.feed.post/3lpygpilx5s2c\n",
      "TopK already exists\n",
      "Got event from at://did:plc:b6vo4imk2ybz2vuyyvo6by6l/app.bsky.feed.post/3lpygpgzgx225\n",
      "TopK already exists\n",
      "Got event from at://did:plc:uahhkr73mtnsffukfdyao744/app.bsky.feed.post/3lpygpisqwk2k\n",
      "TopK already exists\n",
      "Got event from at://did:plc:uwtwxs5b6ahf5kugtmro4ceo/app.bsky.feed.post/3lpygpq7suk2o\n",
      "TopK already exists\n",
      "Got event from at://did:plc:uwtwxs5b6ahf5kugtmro4ceo/app.bsky.feed.post/3lpygpqa2om2o\n",
      "TopK already exists\n",
      "Got event from at://did:plc:kotwcjecfv5xagsoprkqvmu4/app.bsky.feed.post/3lpziyg2lqc23\n",
      "TopK already exists\n",
      "Got event from at://did:plc:pzqcop25zcdyqdz4yc5i6jcz/app.bsky.feed.post/3lpziyepa222v\n",
      "TopK already exists\n",
      "Got event from at://did:plc:3q4c73dozmcipr6kvhd637aq/app.bsky.feed.post/3lpziyfijmc2g\n",
      "TopK already exists\n",
      "Got event from at://did:plc:hfr3fswnqa36j3d5426ifejf/app.bsky.feed.post/3lpziyg5em22f\n",
      "TopK already exists\n",
      "topic-extraction-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating Embeddings for Semantic Search\n",
    "In this section, we'll create embeddings for posts. Embeddings are vector representations of text that capture semantic meaning. They allow us to perform semantic search, which is a search based on meaning rather than exact keyword matching.\n",
    "\n",
    "For example, if I search for:\n",
    "\n",
    "\"Redis is a cool db for Python devs\"\n",
    "\n",
    "I can still match:\n",
    "\n",
    "\"Redis is a great database for Python developers\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting Up the Embedding Model\n",
    "We'll use the Spring AI Transformers library to create embeddings for posts. This library provides a simple API for creating embeddings using transformer models."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:05.696954Z",
     "start_time": "2025-05-25T10:20:05.297999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.springframework.ai:spring-ai-transformers:1.0.0-RC1\")\n",
    "@file:DependsOn(\"ai.djl.huggingface:tokenizers:0.33.0\")"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:05.999281Z",
     "start_time": "2025-05-25T10:20:05.702374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import org.springframework.ai.transformers.TransformersEmbeddingModel\n",
    "\n",
    "val embeddingModel = TransformersEmbeddingModel() // uses all-MiniLM-L6-v2 by default\n",
    "embeddingModel.afterPropertiesSet()"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating an Embedding Handler\n",
    "This function creates a handler that generates embeddings for an event's text and stores them in Redis. The embeddings are stored as binary data in the \"textEmbedding\" field of the event's hash."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:06.058629Z",
     "start_time": "2025-05-25T10:20:06.008250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.lang.Float\n",
    "import java.nio.ByteBuffer\n",
    "import java.nio.ByteOrder\n",
    "\n",
    "fun createEmbedding(input: String): ByteArray {\n",
    "    val embedding = embeddingModel.embed(input)\n",
    "    val embeddingBytes = ByteArray(Float.BYTES * embedding.size)\n",
    "    ByteBuffer.wrap(embeddingBytes).order(ByteOrder.LITTLE_ENDIAN).asFloatBuffer().put(embedding)\n",
    "    return embeddingBytes\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:06.154628Z",
     "start_time": "2025-05-25T10:20:06.081499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val createEmbedding: (Event) -> Pair<Boolean, String> = { event ->\n",
    "    val embeddingBytes = createEmbedding(event.text)\n",
    "    jedisPooled.hset((\"post:\" + event.uri.replace(\"at://did:plc:\", \"\")).encodeToByteArray(), mapOf(\"textEmbedding\".encodeToByteArray() to embeddingBytes))\n",
    "    Pair(true, \"OK\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:06.181245Z",
     "start_time": "2025-05-25T10:20:06.160228Z"
    }
   },
   "cell_type": "code",
   "source": "createConsumerGroup(\"filtered-events\", \"embedding-example\")",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:20:06.253259Z",
     "start_time": "2025-05-25T10:20:06.223813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val bloomFilterName = \"embedding-bf\"\n",
    "createBloomFilter(bloomFilterName)"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:35:01.657563Z",
     "start_time": "2025-05-25T20:34:59.582174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runBlocking {\n",
    "    consumeStream(\n",
    "        streamName = \"filtered-events\",\n",
    "        consumerGroup = \"embedding-example\",\n",
    "        consumer = \"embedding-1\",\n",
    "        handlers = listOf(deduplicate(bloomFilterName), printUri, createEmbedding),\n",
    "        ackFunction = ackAndBfFn(bloomFilterName),\n",
    "        count = 1,\n",
    "        limit = 100\n",
    "    )\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got event from at://did:plc:kotwcjecfv5xagsoprkqvmu4/app.bsky.feed.post/3lpziyg2lqc23\n",
      "Got event from at://did:plc:pzqcop25zcdyqdz4yc5i6jcz/app.bsky.feed.post/3lpziyepa222v\n",
      "Got event from at://did:plc:3q4c73dozmcipr6kvhd637aq/app.bsky.feed.post/3lpziyfijmc2g\n",
      "Got event from at://did:plc:hfr3fswnqa36j3d5426ifejf/app.bsky.feed.post/3lpziyg5em22f\n",
      "embedding-1: No new messages for 2 seconds. Stopping.\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Listing Top Topics and Their Counts"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T10:21:23.096076Z",
     "start_time": "2025-05-25T10:21:23.040747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import redis.clients.jedis.params.ScanParams\n",
    "\n",
    "val jedisScanFn = { cursor: String ->\n",
    "    jedisPooled.scan(cursor, ScanParams().match(\"topics-topk:*\"), \"TOPK-TYPE\")\n",
    "}\n",
    "\n",
    "val keys = mutableListOf<String>()\n",
    "var lastCursor = \"0\"\n",
    "do {\n",
    "    val result = jedisScanFn.invoke(lastCursor)\n",
    "    lastCursor = result.cursor\n",
    "    keys.addAll(result.result)\n",
    "} while (lastCursor != \"0\")\n",
    "\n",
    "keys.forEach {\n",
    "    println(it)\n",
    "    val topics = jedisPooled.topkList(it)\n",
    "    println(topics)\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics-topk:2025-05-25T12:00\n",
      "[AI, Artificial General Intelligence, AI Oracle, Emotional Intelligence, Fortune Telling, Virtual Assistants, Personal Assistant Technologies, Crystal Healing, Post-Pandemic Culture]\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a Redis Search Index\n",
    "In this section, we'll create a Redis Search index to make the enriched events searchable. Redis Search is a module that adds full-text search capabilities to Redis. It allows us to search for events based on their text, topics, and other fields."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating the Index Schema in Code\n",
    "Now we'll create the index schema in code. We'll use the Jedis client to create the schema and the index.\n",
    "\n",
    "The following schema defines the fields that will be indexed. The schema includes:\n",
    "- Text fields for full-text search\n",
    "- Tag fields for exact matching\n",
    "- Vector fields for semantic search\n",
    "\n",
    "```\n",
    "FT.CREATE postIdx ON HASH PREFIX 1 post: SCHEMA\n",
    "        topics        TAG SEPARATOR \"|\"\n",
    "        text          TEXT\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "execution_count": 69,
   "source": [
    "import redis.clients.jedis.search.IndexDefinition\n",
    "import redis.clients.jedis.search.IndexOptions\n",
    "import redis.clients.jedis.search.Schema\n",
    "import redis.clients.jedis.search.schemafields.VectorField.VectorAlgorithm\n",
    "\n",
    "val schema = Schema()\n",
    "    .addTagField(\"topics\", \"|\")\n",
    "    .addTextField(\"text\", 1.0)\n",
    "\n",
    "// Define index options (e.g., prefix)\n",
    "val rule = IndexDefinition()\n",
    "    .setPrefixes(\"post:\")\n",
    "\n",
    "// Create the index\n",
    "try {\n",
    "    jedisPooled.ftCreate(\"postIdx\", IndexOptions.defaultOptions().setDefinition(rule), schema)\n",
    "} catch (e: JedisDataException) {\n",
    "    println(\"Index already exists\")\n",
    "}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Searching the Index\n",
    "Now that we have created the index, we can search for events based on their topics, text, and other fields. In this example, we'll search for events with the topic \"Samba\".\n",
    "\n",
    "Redis Search uses a query language similar to SQL. For example, to search for events with the topic \"machine_learning\", we would use the query `@topics:{machine_learning}`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exact Matching Search"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI|Virtual Assistants|Emotional Intelligence|Personal Assistant Technologies\n",
      "This just affirming my decision to remain Alexa-free. Such an interesting and unexpectedly moving piece.\n",
      "\n",
      "\n",
      "AI|Artificial General Intelligence\n",
      "\"If we continue to feed the AI with data, eventually we'll get artificial general intelligence! We'll achieve consciousness!\"\n",
      "\n",
      "Let's say you and me are both building a house.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 74,
   "source": [
    "//FT.SEARCH postIdx \"@topics:{machine_learning}\"\n",
    "val result = jedisPooled.ftSearch(\n",
    "    \"postIdx\",\n",
    "    \"@topics:{AI}\"\n",
    ")\n",
    "\n",
    "result.documents.forEach { post ->\n",
    "    println(post.get(\"topics\"))\n",
    "    println(post.get(\"text\"))\n",
    "    println(\"\\n\")\n",
    "}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Full Text Search"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"If we continue to feed the AI with data, eventually we'll get artificial general intelligence! We'll achieve consciousness!\"\n",
      "\n",
      "Let's say you and me are both building a house.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 76,
   "source": [
    "//FT.SEARCH postIdx \"@text:Open source\"\n",
    "val result = jedisPooled.ftSearch(\n",
    "    \"postIdx\",\n",
    "    \"@text:If we continue to feed the AI with data\"\n",
    ")\n",
    "\n",
    "result.documents.forEach { post ->\n",
    "    println(post.get(\"text\"))\n",
    "    println(\"\\n\")\n",
    "}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Counting the number of occurrences of a topic with Count-min sketch\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
